{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using natural language processing to improve multiple choice question design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do students solve multiple choice questions? Even if a student knows the answer, a question can be difficult to read. The question might be long or use hard-to-read jargon, or the answers might be very similar, hindering the student’s ability to compare them. How can teachers design multiple choice questions that probe students’ knowledge, without unduly taxing students’ ability to solve complex word problems?\n",
    "\n",
    "In this document, I will use text-based analyses to determine what features of multiple choice questions are difficult for students on exams. There are three main components of my planned analysis. \n",
    "\n",
    "1) <a href='#lda_model'>**Latent Dirichlet Topic modeling**</a>: Identify different semantic question categories (e.g, “memory”, “language”, “perception”, etc.). <br>\n",
    "2) <a href='#nlp'>**Natural Language Processing (NLP) analyses**</a>: Quantify different text properties like length of questions, word frequency in English language, etc.\n",
    "\n",
    "In this notebook, I'll be using **(1)** and **(2)** to design features of questions that predict performance. \n",
    "\n",
    "3) **Mixed effects models in R**: Separately in R, I will compare these predictors and identify features diagnostic of question performance. Given a novel exam, the resulting fitted mixed effects model will allow instructors to identify what questions are worded in ways that will be difficult for students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6/24/2016**-Due to restrictions on making exams public, for the time being I am making this code public but not any data. I'm looking into getting permission to make exams public but for now I created a fake exam to demonstrate how this code works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load our packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "sw=stopwords.words('english')\n",
    "valid_characters = string.ascii_letters + string.digits+string.whitespace\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus--Warning, this is kinda slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "freq_distr=FreqDist([word.lower() for word in  brown.words()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataload'></a>\n",
    "# 0) Load and process exams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load our exams. \"exams_data.csv\" contains information about where the exams are located and what classes they were for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exam_data=pd.read_csv('exams_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>class</th>\n",
       "      <th>exam</th>\n",
       "      <th>instructor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>example_class</td>\n",
       "      <td>example_exam</td>\n",
       "      <td>tflew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                subject          class          exam instructor\n",
       "0  cognitive psychology  example_class  example_exam      tflew"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first exam was from a fake cognitive psychology course taught by me. This directs the code to folders containing files for each exam. For example, the files for \"example_exam\" are located in tests/example_class/example_exam (tests/[class name]/[test name]).\n",
    "\n",
    "Each folder contains three files. The text of the test itself is in **final.txt**. The answer key is in **final_answers.txt** and the students' responses are in **final_responses.xls** (TAs in our department tend to save these as Excel files using the Remark system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_fold='tests'\n",
    "\n",
    "all_subject=exam_data.subject\n",
    "all_instructor=exam_data.instructor\n",
    "all_tests=[]\n",
    "all_anskey=[]\n",
    "all_resp=[]\n",
    "\n",
    "for ind,curr_test in enumerate(exam_data.iterrows()):\n",
    "    class_name=curr_test[1]['class']\n",
    "    exam_name = curr_test[1]['exam']\n",
    "    test_fold= os.path.join(data_fold,class_name,exam_name)\n",
    "\n",
    "    # load test\n",
    "    test_fname=os.path.join(test_fold,exam_name+'.txt')\n",
    "    with open(test_fname,'rb') as test_txt:\n",
    "        test=test_txt.readlines()\n",
    "        all_tests.append(test)\n",
    "    \n",
    "    # load answer key\n",
    "    anskey_fname=os.path.join(test_fold,exam_name+'_answers'+'.csv')\n",
    "    all_anskey.append(pd.read_csv(anskey_fname))\n",
    "    \n",
    "    # load student responses\n",
    "    xls_fname=os.path.join(test_fold,exam_name+'_responses'+'.xls')\n",
    "    resp=pd.read_excel(xls_fname)\n",
    "\n",
    "    # create unique random student ID. UCSD's psych grading system uses the last 4 digits of students' ID\n",
    "    resp.loc[:,'Last4_ID']=[str(ind)+'_'+str(i) for i in range(len(resp)) ] \n",
    "    all_resp.append(resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing and test schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's figure out what are the questions and answers.\n",
    "\n",
    "Currently, my code assumes each questions is a number followed by a period (\"1. \") and each answer is lowercase letter followed by a parentheses ( \"a) \"). Also, lines are split by **\\r, because I converted from MS Word**. If exams have a different format, you'll have to adjust the test_key and curr_test.split('\\r') sections.\n",
    "\n",
    "txt2schema() figures out the questions and answers and melts them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def txt2schema(curr_test):\n",
    "    curr_test=curr_test.split('\\r') \n",
    "    test_key={'question':'[\\d]+\\. [a-zA-Z]*','answer':'[abcde]\\)','question_num':'[\\d]+'}\n",
    "\n",
    "    all_q_num=[]\n",
    "    all_question=[]\n",
    "    all_answer=[]\n",
    "    for line in curr_test:\n",
    "        # check if question\n",
    "        q_search=re.findall(test_key['question'],line)\n",
    "        is_q=len(q_search)==1\n",
    "\n",
    "        # check if answer\n",
    "        a_search=re.findall(test_key['answer'],line)\n",
    "        is_a=len(a_search)==1\n",
    "\n",
    "        if is_q:\n",
    "            q_num=re.findall(test_key['question_num'],line)[0]\n",
    "            curr_question=line[3:]\n",
    "        elif is_a:\n",
    "            all_q_num.append(q_num)\n",
    "            all_question.append(curr_question)\n",
    "            all_answer.append(line[3:])\n",
    "    test_schema=pd.DataFrame({'q_num':all_q_num,'question':all_question,'answer':all_answer})\n",
    "    return test_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **process_text()** stems words in the questions and answers to help our NLP analyses later on. For example, if one answer uses the word \"neuroscience\" and another uses the word \"neural\", we would want to recognize those answers are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_text(txt):\n",
    "    # get rid of punctuation\n",
    "    txt=''.join([i for i in txt if i in valid_characters])\n",
    "    \n",
    "    # split into words\n",
    "    txt_split=txt.lower().decode('latin-1').split(' ')\n",
    "    \n",
    "    # remove stopwords\n",
    "    txt_split=[i for i in txt_split if (not (i in sw))]\n",
    "    \n",
    "    # create stemmer to stem words\n",
    "    stemmer=SnowballStemmer(\"english\")\n",
    "    proc_text = ' '.join([stemmer.stem(i) for i in txt_split])\n",
    "    return proc_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I'm going to save all of our results from each exam to a single dataframe. This dataframe will store all of our processed data as I move forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_schema=pd.DataFrame({})\n",
    "\n",
    "for ind,(curr_test,curr_subj,curr_instructor) in enumerate(zip(all_tests,all_subject,all_instructor)):\n",
    "    curr_test_text=curr_test[0]\n",
    "    curr_schema=txt2schema(curr_test_text)\n",
    "    curr_schema.loc[:,'proc_question']=curr_schema.loc[:,'question'].apply(process_text)  \n",
    "    curr_schema.loc[:,'proc_answer']=curr_schema.loc[:,'answer'].apply(process_text)  \n",
    "    curr_schema.loc[:,'exam']=str(ind) # give each exam a unique id\n",
    "    curr_schema.loc[:,'subject']=curr_subj\n",
    "    curr_schema.loc[:,'instructor']=curr_instructor\n",
    "    all_schema=all_schema.append(curr_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>q_num</th>\n",
       "      <th>question</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_answer</th>\n",
       "      <th>exam</th>\n",
       "      <th>subject</th>\n",
       "      <th>instructor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working memory capacity is limited</td>\n",
       "      <td>1</td>\n",
       "      <td>Change detection demonstrates</td>\n",
       "      <td>chang detect demonstr</td>\n",
       "      <td>work memori capac limit</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long term memory capacity is limited</td>\n",
       "      <td>1</td>\n",
       "      <td>Change detection demonstrates</td>\n",
       "      <td>chang detect demonstr</td>\n",
       "      <td>long term memori capac limit</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People are lazy</td>\n",
       "      <td>1</td>\n",
       "      <td>Change detection demonstrates</td>\n",
       "      <td>chang detect demonstr</td>\n",
       "      <td>peopl lazi</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remembering scenes is easy</td>\n",
       "      <td>1</td>\n",
       "      <td>Change detection demonstrates</td>\n",
       "      <td>chang detect demonstr</td>\n",
       "      <td>rememb scene easi</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensation is our representation of raw stimuli...</td>\n",
       "      <td>2</td>\n",
       "      <td>The difference between sensation and perceptio...</td>\n",
       "      <td>differ sensat percept</td>\n",
       "      <td>sensat represent raw stimuli percept process r...</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer q_num  \\\n",
       "0                 Working memory capacity is limited     1   \n",
       "1               Long term memory capacity is limited     1   \n",
       "2                                    People are lazy     1   \n",
       "3                         Remembering scenes is easy     1   \n",
       "4  Sensation is our representation of raw stimuli...     2   \n",
       "\n",
       "                                            question          proc_question  \\\n",
       "0                      Change detection demonstrates  chang detect demonstr   \n",
       "1                      Change detection demonstrates  chang detect demonstr   \n",
       "2                      Change detection demonstrates  chang detect demonstr   \n",
       "3                      Change detection demonstrates  chang detect demonstr   \n",
       "4  The difference between sensation and perceptio...  differ sensat percept   \n",
       "\n",
       "                                         proc_answer exam  \\\n",
       "0                            work memori capac limit    0   \n",
       "1                       long term memori capac limit    0   \n",
       "2                                         peopl lazi    0   \n",
       "3                                  rememb scene easi    0   \n",
       "4  sensat represent raw stimuli percept process r...    0   \n",
       "\n",
       "                subject instructor  \n",
       "0  cognitive psychology      tflew  \n",
       "1  cognitive psychology      tflew  \n",
       "2  cognitive psychology      tflew  \n",
       "3  cognitive psychology      tflew  \n",
       "4  cognitive psychology      tflew  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_schema.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map questions to responses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine our answer key with the student responses so we can figure out students' performance on each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_q(txt):\n",
    "    return txt[1:]\n",
    "\n",
    "def lower_txt(txt):\n",
    "    try:\n",
    "        return txt.lower()\n",
    "    except:\n",
    "        return txt\n",
    "\n",
    "all_resp_ans=pd.DataFrame({})\n",
    "for ind,(curr_resp,curr_ans) in enumerate(zip(all_resp,all_anskey)):\n",
    "    # Get responses\n",
    "    curr_exam=all_schema.loc[all_schema.exam==str(ind),:]\n",
    "    num_q=max([int(i) for i in np.unique(curr_exam.q_num)])\n",
    "    curr_resp=all_resp[ind].iloc[:,1:(1+num_q+1)]\n",
    "    curr_id=all_resp[ind].iloc[:,-1]\n",
    "    curr_resp.loc[:,'Last4_ID']=curr_id\n",
    "    curr_resp_melt=pd.melt(curr_resp, id_vars=['Last4_ID'])\n",
    "\n",
    "    curr_resp_melt.loc[:,'variable']=curr_resp_melt.loc[:,'variable'].apply(remove_q)\n",
    "    curr_resp_melt.loc[:,'value']=curr_resp_melt.loc[:,'value'].apply(lower_txt)\n",
    "    curr_resp_melt.loc[:,'exam']=str(ind)\n",
    "    curr_resp_melt.columns=['Last4_ID','q_num','response','exam']    \n",
    "    \n",
    "    # Get answers\n",
    "    curr_answer=curr_ans.loc[:,['q_num','answer']]\n",
    "    curr_answer.loc[:,'q_num']=curr_answer.loc[:,'q_num'].apply(str)\n",
    "    \n",
    "    # Merge the responses and answers\n",
    "    curr_resp=pd.merge(curr_resp_melt,curr_answer,on='q_num')\n",
    "    curr_resp.loc[:,'correct']=curr_resp.loc[:,'response']==curr_resp.loc[:,'answer']\n",
    "\n",
    "    all_resp_ans=all_resp_ans.append(curr_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last4_ID</th>\n",
       "      <th>q_num</th>\n",
       "      <th>response</th>\n",
       "      <th>exam</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Last4_ID q_num response exam answer correct\n",
       "0      0_0     1        b    0      a   False\n",
       "1      0_1     1        a    0      a    True\n",
       "2      0_2     1        a    0      a    True\n",
       "3      0_3     1        b    0      a   False\n",
       "4      0_4     1        a    0      a    True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_resp_ans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lda_model'></a>\n",
    "# 1) Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's try to figure out the topics of the questions using Latent Dirichlet allocation modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function takes a fitted LDA and returns a dataframe with the top n features from each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_features(lda_model,tf_feature_names,n,verbose=False):\n",
    "    features_weights=lda_model.components_\n",
    "    top_features={}\n",
    "    for w_i,weights in enumerate(features_weights):\n",
    "        \n",
    "        best_features=[]\n",
    "        ranks=len(weights)-sp.stats.rankdata(weights)\n",
    "        for best in range(n):\n",
    "            feature=tf_feature_names[np.where(ranks==best)[0][0]]\n",
    "            best_features.append(feature)\n",
    "        if verbose:\n",
    "            print 'Component '+str(w_i)\n",
    "            print ' ,'.join(best_features)\n",
    "        top_features['Component '+str(w_i)]=best_features\n",
    "    top_features_df=pd.DataFrame(top_features).transpose()\n",
    "    top_features_df.loc[:,'topic']=range(len(features_weights))\n",
    "    return top_features_df\n",
    "\n",
    "#top_features=get_top_features(lda_model,tf_feature_names,10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And two helper functions. concat_txt() combines the question and all the answers into a singles string that the LDA can infer the topic from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_txt(txt):\n",
    "    return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This for-loop does the heavy lifting. It iterates over each subject and runs the topic model on the items aggregated from all the exams from that subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting cognitive psychology\n",
      "Component 0\n",
      "peopl ,dress ,color ,differ ,limit ,memori ,capac ,make ,decis ,avers\n",
      "Component 1\n",
      "languag ,sensat ,percept ,process ,represent ,object ,prime ,domin ,visual ,item\n",
      "Component 2\n",
      "bias ,reli ,heurist ,decis ,make ,quick ,primarili ,depth ,learn ,right\n",
      "Component 3\n",
      "area ,damag ,inabl ,reflect ,broca ,wernick ,fusiform ,produc ,sentenc ,face\n"
     ]
    }
   ],
   "source": [
    "unique_subjects=np.unique(all_subject)\n",
    "\n",
    "# get all exams from current subject\n",
    "all_labeled=pd.DataFrame({})\n",
    "all_topic=pd.DataFrame({})\n",
    "for subject in unique_subjects:\n",
    "    print 'Fitting '+subject\n",
    "    \n",
    "    # Iterate over all exams for this subject\n",
    "    subject_schema=all_schema.loc[all_schema.subject==subject,:]\n",
    "    ind_ans=subject_schema.loc[:,['exam', 'q_num','proc_answer']].groupby(['exam', 'q_num']).aggregate({'proc_answer':concat_txt}).reset_index()\n",
    "    ind_qs=subject_schema.loc[:,['exam','q_num', 'proc_question']].drop_duplicates().reset_index()\n",
    "    ind_item=pd.merge(ind_qs,ind_ans,on=['exam','q_num'])\n",
    "    ind_item.loc[:,'item']=ind_item.proc_question+' '+ind_item.proc_answer\n",
    "            \n",
    "#     # Fit count vectorizer-Finds frequent words and \n",
    "#     n_features=25\n",
    "#     tf_vectorizer = CountVectorizer(min_df=2, max_features=n_features,stop_words='english')\n",
    "\n",
    "    # Use Tf-Idf frequency. Words that are frequent (tf) but not in a lot of documents (idf)\n",
    "    tf_vectorizer=TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    tf = tf_vectorizer.fit_transform(ind_item.item)\n",
    "    \n",
    "    # Fit LDA on all test\n",
    "    lda_model=LatentDirichletAllocation(n_topics=4)\n",
    "    lda_model.fit(tf);\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    top_features=get_top_features(lda_model,tf_feature_names,10,verbose=True)  \n",
    "    top_features.loc[:,'subject']=subject\n",
    "    top_features.loc[:,'subject_topic']=[subject+'_'+str(t) for t in range(len(top_features))]    \n",
    "    top_features.reset_index(inplace=True)\n",
    "    all_topic=all_topic.append(top_features)\n",
    "    \n",
    "    # And predict topic\n",
    "    ind_item.loc[:,'topic']=[subject+'_'+str(np.argmax(items))  for items in lda_model.transform(tf)]\n",
    "    all_labeled=all_labeled.append(ind_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_topic is a dataframe containing our topics and the diagnostic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>topic</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Component 0</td>\n",
       "      <td>peopl</td>\n",
       "      <td>dress</td>\n",
       "      <td>color</td>\n",
       "      <td>differ</td>\n",
       "      <td>limit</td>\n",
       "      <td>memori</td>\n",
       "      <td>capac</td>\n",
       "      <td>make</td>\n",
       "      <td>decis</td>\n",
       "      <td>avers</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>cognitive psychology_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Component 1</td>\n",
       "      <td>languag</td>\n",
       "      <td>sensat</td>\n",
       "      <td>percept</td>\n",
       "      <td>process</td>\n",
       "      <td>represent</td>\n",
       "      <td>object</td>\n",
       "      <td>prime</td>\n",
       "      <td>domin</td>\n",
       "      <td>visual</td>\n",
       "      <td>item</td>\n",
       "      <td>1</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>cognitive psychology_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Component 2</td>\n",
       "      <td>bias</td>\n",
       "      <td>reli</td>\n",
       "      <td>heurist</td>\n",
       "      <td>decis</td>\n",
       "      <td>make</td>\n",
       "      <td>quick</td>\n",
       "      <td>primarili</td>\n",
       "      <td>depth</td>\n",
       "      <td>learn</td>\n",
       "      <td>right</td>\n",
       "      <td>2</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>cognitive psychology_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Component 3</td>\n",
       "      <td>area</td>\n",
       "      <td>damag</td>\n",
       "      <td>inabl</td>\n",
       "      <td>reflect</td>\n",
       "      <td>broca</td>\n",
       "      <td>wernick</td>\n",
       "      <td>fusiform</td>\n",
       "      <td>produc</td>\n",
       "      <td>sentenc</td>\n",
       "      <td>face</td>\n",
       "      <td>3</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>cognitive psychology_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        0       1        2        3          4        5  \\\n",
       "0  Component 0    peopl   dress    color   differ      limit   memori   \n",
       "1  Component 1  languag  sensat  percept  process  represent   object   \n",
       "2  Component 2     bias    reli  heurist    decis       make    quick   \n",
       "3  Component 3     area   damag    inabl  reflect      broca  wernick   \n",
       "\n",
       "           6       7        8      9  topic               subject  \\\n",
       "0      capac    make    decis  avers      0  cognitive psychology   \n",
       "1      prime   domin   visual   item      1  cognitive psychology   \n",
       "2  primarili   depth    learn  right      2  cognitive psychology   \n",
       "3   fusiform  produc  sentenc   face      3  cognitive psychology   \n",
       "\n",
       "            subject_topic  \n",
       "0  cognitive psychology_0  \n",
       "1  cognitive psychology_1  \n",
       "2  cognitive psychology_2  \n",
       "3  cognitive psychology_3  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpretting the results of the LDA, note that the model interprets each question as arising from a mixture of possible of topic. Here I've just chosen to assign each item to its most likely topic (there might be some fun analyses to do looking at the difficulty of cross-topic questions). Each topic in turn is composed of common words with different weights. In all_topic, I've arranged the top ten words from most (0) to least (9) important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can add the topic labels to our main all_schema dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_schema=pd.merge(all_schema,all_labeled.loc[:,['q_num','exam','topic']],on=['q_num','exam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's get an idea of how frequently questions in each topic occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "cognitive psychology_0    3\n",
       "cognitive psychology_1    3\n",
       "cognitive psychology_2    1\n",
       "cognitive psychology_3    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_schema.loc[:,['topic','q_num','exam']].drop_duplicates().groupby('topic').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Did difficulty vary by topic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see if we've done anything of significance--did students have more difficulty with certain topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp_topic=pd.merge(all_resp_ans,all_schema.loc[:,['exam','q_num','topic']],on=['q_num','exam'])\n",
    "topic_performance=resp_topic.loc[:,['topic','correct']].groupby('topic').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Component 0</td>\n",
       "      <td>differ</td>\n",
       "      <td>peopl</td>\n",
       "      <td>reflect</td>\n",
       "      <td>languag</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>process</td>\n",
       "      <td>rememb</td>\n",
       "      <td>decis</td>\n",
       "      <td>make</td>\n",
       "      <td>memori</td>\n",
       "      <td>cognitive psychology_0</td>\n",
       "      <td>0.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Component 2</td>\n",
       "      <td>languag</td>\n",
       "      <td>memori</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>process</td>\n",
       "      <td>rememb</td>\n",
       "      <td>reflect</td>\n",
       "      <td>peopl</td>\n",
       "      <td>differ</td>\n",
       "      <td>make</td>\n",
       "      <td>decis</td>\n",
       "      <td>cognitive psychology_2</td>\n",
       "      <td>0.045752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Component 3</td>\n",
       "      <td>peopl</td>\n",
       "      <td>make</td>\n",
       "      <td>decis</td>\n",
       "      <td>process</td>\n",
       "      <td>differ</td>\n",
       "      <td>rememb</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>reflect</td>\n",
       "      <td>languag</td>\n",
       "      <td>memori</td>\n",
       "      <td>cognitive psychology_3</td>\n",
       "      <td>0.026144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        0       1         2        3         4        5  \\\n",
       "0  Component 0   differ   peopl   reflect  languag  demonstr  process   \n",
       "1  Component 2  languag  memori  demonstr  process    rememb  reflect   \n",
       "2  Component 3    peopl    make     decis  process    differ   rememb   \n",
       "\n",
       "          6        7        8       9                 topic_y   correct  \n",
       "0    rememb    decis     make  memori  cognitive psychology_0  0.078431  \n",
       "1     peopl   differ     make   decis  cognitive psychology_2  0.045752  \n",
       "2  demonstr  reflect  languag  memori  cognitive psychology_3  0.026144  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results=pd.merge(top_features,topic_performance,left_on='subject_topic', right_on='topic').sort_values('correct',ascending=False)\n",
    "topic_results.drop(['topic_x','subject', 'subject_topic'],axis=1,inplace=True)\n",
    "topic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nlp'></a>\n",
    "# 2) NLP analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have our data processed and tagged, let's start creating some more complex features from our text. Coming up we've got:\n",
    "\n",
    "a) <a href='#s_a'>Question length</a>  <br />\n",
    "b) <a href='#s_b'>Answer length</a>  <br />\n",
    "c) <a href='#s_c'>English word frequency</a>  <br />\n",
    "d) <a href='#s_d'><a href='#s_a'>All/None of the above questions</a>  <br />\n",
    "e) <a href='#s_e'>Similarity of answers to each other</a>  <br />\n",
    "f) <a href='#s_f'>Similarity of the answers to the question</a>  <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s_a'></a>\n",
    "## a) Question length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the length of questions affect their difficulty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118d66b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFVCAYAAACuK+XmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFFNJREFUeJzt3X1slfXZwPHrlPJOVxhDH6MEFNfM2MxlXRYToyFGN9hL\nMhT+wAEjaaboNIz4wutEERXcspktm8NsM1GfjGyRxc1nL9H4soyY6U42J/qg2cRmq4KAyloq2NLz\n/LGMMR/sKaXnOnDO5/MXoXfPuX7nd5cv9ym9KZRKpVIAAGkaqj0AANQb8QWAZOILAMnEFwCSiS8A\nJBNfAEjWWO6Avr6+WL58eXR2dkZjY2PcdtttceaZZ2bMBgA1qeyV71NPPRX9/f2xefPmuOaaa+Jb\n3/pWxlwAULPKxnf69Olx6NChKJVK0dXVFSNHjsyYCwBqVtm3ncePHx9///vfY9asWfH222/Hpk2b\nMuYCgJpVKHd7yQ0bNsTo0aNj2bJlsWvXrli0aFH84he/iFGjRh31+GKxWJFBAeBE1dbWdkzHl73y\nbW5ujsbGfx7W1NQUfX190d/fP6xD1JJisVi366/ntUdYv/WfHOt/+eWX46oNj8WESadXe5QBdb/V\nGZtWXBItLS3VHqWsoVx0lo3vl770pVi1alV88YtfjL6+vrj++utjzJgxQxoQABhEfMeNGxd33313\nxiwAUBfcZAMAkokvACQTXwBIJr4AkEx8ASCZ+AJAMvEFgGTiCwDJxBcAkokvACQTXwBIJr4AkEx8\nASCZ+AJAMvEFgGTiCwDJxBcAkokvACQTXwBIJr4AkEx8ASCZ+AJAMvEFgGTiCwDJxBcAkokvACQT\nXwBIJr4AkEx8ASCZ+AJAMvEFgGSN5Q742c9+Flu2bIlCoRAHDx6M7du3x9atW2PChAkZ8wFAzSkb\n3zlz5sScOXMiImLdunUxd+5c4QWA4zDot52ff/75+Mtf/hLz5s2r5DwAUPMKpVKpNJgDr7vuuli4\ncGF88pOfHPC4YrE4LIMBMPw6OjriO4/sjAmTTq/2KAPqfqszrvvcf8W0adOqPcqgtLW1HdPxZd92\njojo6uqKV199tWx4hzpELSkWi3W7/npee4T1W//Jsf6mpqaIR3ZWe4xBaW1tjZaWlmqPUdZQLjoH\n9bbzs88+G+eff/4xPzgA8P8NKr47duyIqVOnVnoWAKgLg3rbub29vdJzAEDdcJMNAEgmvgCQTHwB\nIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNf\nAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMka\nB3PQvffeG48//nj09vbGFVdcEZdffnml5wKAmlU2vs8880z88Y9/jM2bN0dPT0/86Ec/ypgLAGpW\n2fj+7ne/i5aWlrjmmmti//79cdNNN2XMBQA1q2x833rrrXjttddi06ZN8be//S2uvvrq+PWvf50x\nGwDUpLLxnThxYsyYMSMaGxvjzDPPjNGjR8ebb74ZH/zgB9/3c4rF4rAOebKp5/XX89ojrN/6T/z1\nd3R0VHuEQdu2bVt0dXVVe4yKKBvftra2eOCBB2Lx4sWxa9euOHDgQEyaNKns59SrYrFYt+uv57VH\nWL/1nxzrb2pqinhkZ7XHGJTW1tZoaWmp9hhlDeUvXWXjO3PmzPjDH/4Qc+fOjVKpFGvXro1CoTCk\nAQGAQf6o0Q033FDpOQCgbrjJBgAkE18ASCa+AJBMfAEgmfgCQDLxBYBk4gsAycQXAJKJLwAkE18A\nSCa+AJBMfAEgmfgCQDLxBYBk4gsAycQXAJKJLwAkE18ASCa+AJBMfAEgmfgCQDLxBYBk4gsAycQX\nAJKJLwAkE18ASCa+AJBMfAEgmfgCQDLxBYBkjYM56LLLLosJEyZERMQZZ5wRd9xxR0WHAoBaVja+\n7777bkRE3H///RUfBgDqQdm3nbdv3x49PT3R3t4eixcvjueeey5jLgCoWWWvfMeMGRPt7e0xb968\nePXVV+PLX/5y/OY3v4mGBt8uBoChKBvf6dOnx7Rp0w7/euLEibF79+449dRT3/dzisXi8E14Eqrn\n9dfz2iOs3/pP/PV3dHRUe4RB27ZtW3R1dVV7jIooG9+HHnooXn755Vi7dm3s2rUr9u/fH1OmTBnw\nc9ra2oZtwJNNsVis2/XX89ojrN/6T471NzU1RTyys9pjDEpra2u0tLRUe4yyhvKXrrLxnTt3bqxc\nuTKuuOKKaGhoiDvuuMNbzgBwHMrGd+TIkfGNb3wjYxYAqAsuYQEgmfgCQDLxBYBk4gsAycQXAJKJ\nLwAkE18ASCa+AJBMfAEgmfgCQDLxBYBk4gsAycQXAJKJLwAkE18ASCa+AJBMfAEgmfgCQDLxBYBk\n4gsAycQXAJKJLwAkE18ASCa+AJBMfAEgmfgCQDLxBYBk4gsAycQXAJKJLwAkE18ASDao+O7duzdm\nzpwZO3bsqPQ8AFDzysa3r68v1q5dG2PGjMmYBwBqXmO5AzZu3Bjz58+PTZs2ZcxDFRw6dCj++te/\nHvfjdHR0RFNT0zBMdHSHDh2KiIgRI0ZU7DmOx5HrnzFjxgk758lmuM7PSnvllVdi3LhxJ/y+nyzv\nYJb6+0+aWYdiwPhu2bIlJk+eHBdccEF8//vfH/SDFovF4x5sIN/ctDkORuX+kD9+/xMREdOnjIz5\nl32qyrOU19HRERv/+88xrvmU43+wR3Ye/2O8j71//98Y2zR5eOaslEd2Rs++N2L5Fz8a06ZNq/Y0\n6SrxtT+s52cF/fP8fOGkmHPyGedUe4yy3unaHTffuyfGNZ/Yf/Hq2fdGfG/V54/588rGt1AoxNat\nW2P79u2xfPnyuOeee2Ly5MkDPmhbW9sxD3IsGsc9Ff8YMaOizzEcxn3gjYq/FsOhqakpxjXvjAmT\nTq/2KAPq2bcrxjWfcsLPGRHR2toaLS0t1R4jVbFYrMj57vwcXj37dlV7hEE7GV7PoRowvg8++ODh\nXy9cuDDWrVtXNrwAwMAG/aNGhUKhknMAQN0o+w+u/uX++++v5BwAUDfcZAMAkokvACQTXwBIJr4A\nkEx8ASCZ+AJAMvEFgGTiCwDJxBcAkokvACQTXwBIJr4AkEx8ASCZ+AJAMvEFgGTiCwDJxBcAkokv\nACQTXwBIJr4AkEx8ASCZ+AJAMvEFgGTiCwDJxBcAkokvACQTXwBIJr4AkEx8ASCZ+AJAssZyB/T3\n98eaNWtix44d0dDQELfeemucffbZGbMBQE0qe+X7+OOPR6FQiB//+MexdOnS+OY3v5kxFwDUrLJX\nvpdccklcfPHFERHR2dkZzc3NFR8KAGpZ2fhGRDQ0NMSKFSvisccei29/+9uVngkAatqg4hsRsWHD\nhti7d2/MmzcvfvnLX8aYMWPe99hisTgsw72f7u7uiJPgAnz37j0Vfy2GQ0dHR7VHqDnbtm2Lrq6u\nao+RrhLnu/OTWlQ2vg8//HDs2rUrrrzyyhg9enQ0NDREQ8PA3ypua2sbtgGPZsKEp+LNij7D8Jgy\n5UMVfy2GQ1NTU8QjO6s9Rk1pbW2NlpaWao+RqlgsVuR8d35Si8rG91Of+lSsXLkyFixYEH19fbF6\n9eoYNWpUxmwAUJPKxnfs2LFx9913Z8wCAHXBTTYAIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgm\nvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCS\niS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJGsc6IN9fX2xatWq6OzsjN7e3liy\nZElcfPHFWbMBQE0aML4///nPY9KkSXHXXXfFvn374gtf+IL4AsBxGjC+s2fPjlmzZkVERH9/fzQ2\nDng4ADAIA9Z07NixERHR3d0dS5cujWXLlqUMBQC1rOyl7Ouvvx7XXnttLFiwID7zmc8M6kGLxeJx\nDzaQ7u7uiOaKPsWw2L17T8Vfi+HQ0dFR7RFqzrZt26Krq6vaY6SrxPnu/KQWDRjfPXv2RHt7e9x8\n881x/vnnD/pB29rajnuwgUyY8FS8WdFnGB5Tpnyo4q/FcGhqaop4ZGe1x6gpra2t0dLSUu0xUhWL\nxYqc785PatGAP2q0adOm+Mc//hHf+973YuHChbFo0aJ49913s2YDgJo04JXv6tWrY/Xq1VmzAEBd\ncJMNAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOIL\nAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4\nAkAy8QWAZOILAMnEFwCSDSq+zz33XCxcuLDSswBAXWgsd8APfvCDePjhh2P8+PEZ8wBAzSt75Ttt\n2rT47ne/mzELANSFsle+l156aXR2dh7TgxaLxSEPNBjd3d0RzRV9imGxe/eeir8Ww6Gjo6PaI9Sc\nbdu2RVdXV7XHSFeJ8935SS0qG9+haGtrq8TDHjZhwlPxZkWfYXhMmfKhir8Ww6GpqSnikZ3VHqOm\ntLa2RktLS7XHSFUsFityvjs/qUWD/tfOpVKpknMAQN0YdHwLhUIl5wCAujGo+J5++umxefPmSs8C\nAHXBTTYAIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCS\niS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJBNfAEgmvgCQTHwBIJn4AkAy8QWA\nZOILAMnEFwCSiS8AJGssd0CpVIpbbrklXnrppRg1alTcfvvtMXXq1IzZAKAmlb3yfeyxx+Ldd9+N\nzZs3x/XXXx933nlnxlwAULPKxrdYLMaFF14YERHnnXdebNu2reJDAUAtK/u2c3d3dzQ1Nf37Exob\no7+/Pxoaqvft4r6e3VHoP1C15x/IwQMHY/SY0RERsae/J15++eUqT1Tejh07omffG9Ueo6x3ut6M\niEK1xyirZ98bsWPHjmqPka6jo+M//qwYLs7P4WXO4TXUc7NQKpVKAx2wYcOG+NjHPhazZs2KiIiZ\nM2fGk08++b7HF4vFIQ0CACertra2Yzq+7JXvxz/+8XjiiSdi1qxZ8ac//SlaWlqGdQAAqDdlr3yP\n/NfOERF33nlnnHnmmSnDAUAtKhtfAGB4uckGACQTXwBIJr4AkEx8ASBZ2R81ej99fX2xatWq6Ozs\njN7e3liyZEmcffbZsWLFimhoaIgPf/jDsXbt2uGc9YRytPWfdtppcdVVV8X06dMjImL+/Pkxe/bs\n6g5aIf39/bFmzZrYsWNHNDQ0xK233hqjRo2qm/0/2vp7e3vrZv8jIvbu3RuXX3553HfffTFixIi6\n2ft/OXL9Bw4cqKu9v+yyy2LChAkREXHGGWfEkiVL6mr/37v+hQsXHvv+l4booYceKt1xxx2lUqlU\n2rdvX2nmzJmlJUuWlJ599tlSqVQq3XzzzaVHH310qA9/wjty/W+//XZp5syZpZ/+9Kel++67r7qD\nJXn00UdLq1atKpVKpdLvf//70tVXX11X+3+09f/kJz+pm/3v7e0tfeUrXyl9+tOfLr3yyit1tfel\n0v9ffz3t/cGDB0tz5sz5j9+rp/0/2vqHsv9Dftt59uzZsXTp0oiIOHToUIwYMSJefPHF+MQnPhER\nERdddFE8/fTTQ334E96R6+/v74/GxsZ44YUX4oknnogFCxbE6tWro6enp8pTVs4ll1wSt912W0RE\nvPbaa9Hc3FxX+3/k+js7O6O5ubmu9n/jxo0xf/78OOWUU6JUKtXV3kf85/ojIl544YV48skn62Lv\nt2/fHj09PdHe3h6LFy+O5557rq72/2jrH8r+Dzm+Y8eOjXHjxkV3d3csXbo0li1bFqUjfmR4/Pjx\n0dXVNdSHP+G9d/1f/epX46Mf/WgsX748HnzwwZg6dWp85zvfqfaYFdXQ0BArVqyI9evXx+c+97m6\n2v+If6//9ttvj89//vNx3nnn1cX+b9myJSZPnhwXXHDB4T3v7+8//PFa3/v3rr9UKsV5550XN910\nU83vfUTEmDFjor29PX74wx/GLbfcEjfccENdfe0fbf3nnnvuMe//kL/nGxHx+uuvx7XXXhsLFiyI\nz372s/H1r3/98Mf2798fH/jAB47n4U94711/V1fX4RvLX3rppbF+/foqT1h5GzZsiL1798bcuXPj\n4MGDh3+/HvY/4t/rnzdvXmzevPnwlVAt7/+WLVuiUCjE1q1b46WXXorly5fHW2+9dfjjtb73R65/\n+/btsWLFirjnnnti8uTJEVHbex8RMX369Jg2bdrhX0+cODFefPHFwx+v9f0/2vovuuiiOPXUUyNi\n8Ps/5CvfPXv2RHt7e9x4440xZ86ciIg455xz4tlnn42IiN/+9rc1fZ/no62/vb09nn/++YiIePrp\np+Pcc8+t5ogV9fDDD8e9994bERGjR4+OhoaGaG1tjWeeeSYian//37v+QqEQ1113Xfz5z3+OiNre\n/wcffDAeeOCBeOCBB+IjH/lI3HXXXXHhhRfWzdf+kes/55xzYuPGjXH11VfXxd5HRDz00EOxYcOG\niIjYtWtXdHd3xwUXXFA3X/tHW/8111xzzPs/5NtL3n777fGrX/0qzjrrrCiVSlEoFGL16tWxfv36\n6O3tjRkzZsT69eujUDjx/0uooTja+pctWxZ33XVXjBw5MqZMmRLr1q2L8ePHV3vUinjnnXdi5cqV\nsWfPnujr64urrroqzjrrrFizZk1d7P9713/llVfGaaedFuvWrauL/f+XRYsWxa233hqFQiG+9rWv\n1cXeH+lf6z9w4EDd7H1vb2+sXLkyXnvttWhoaIgbb7wxJk6cWDdf++9d/w033BCjR48+5v13b2cA\nSOYmGwCQTHwBIJn4AkAy8QWAZOILAMnEFwCSiS8AJPs/UlvnPCNeC5wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a6fa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_schema.loc[:,'q_len']=all_schema.loc[:,'question'].apply(len)\n",
    "all_schema.loc[:,'q_len'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s_b'></a>\n",
    "## b) Answer length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the length of answers affect students' performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119a9e510>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFVCAYAAACuK+XmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTHwBIJn4AkAy8QWAZP8PhrETlp65LJAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119c19810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_schema.loc[:,'ans_len']=all_schema.loc[:,'answer'].apply(len)\n",
    "ans_len=all_schema.loc[:,['exam', 'q_num','ans_len']].groupby(['exam', 'q_num']).mean().reset_index() # average answer length\n",
    "all_schema=all_schema.drop('ans_len',axis=1)\n",
    "all_schema=pd.merge(all_schema,ans_len,on=['exam', 'q_num'])\n",
    "all_schema.loc[:,'ans_len'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s_c'></a>\n",
    "## c) English word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did infrequency and/or jargony words hurt students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_word_freq(txt):\n",
    "    txt=[t.lower() for t in txt.split(' ') if not (t in sw) ]\n",
    "    freq=[freq_distr[t]+1 for t in txt]\n",
    "    return np.mean(np.log10(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7232199139484699"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_freq('How now brown cow?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119a9e650>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFVCAYAAAA30zxTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w+9dJK/n4Q3DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11966fe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item_combined=all_schema.loc[:,['exam', 'q_num','answer']].groupby(['exam', 'q_num']).aggregate(concat_txt).reset_index()\n",
    "temp=pd.merge(item_combined,all_schema.loc[:,['exam', 'q_num','question']],on=['exam', 'q_num'],how='left')\n",
    "temp.loc[:,'all_words']=temp.loc[:,'question'] +' '+temp.loc[:,'answer']\n",
    "\n",
    "concat_answer=temp # need later\n",
    "\n",
    "temp.loc[:,'log_freq']=temp.loc[:,'all_words'].apply(get_word_freq)\n",
    "#curr_schema_topic=pd.merge(curr_schema_topic,ind_item.loc[:,['q_num','log_freq']],on='q_num')\n",
    "temp.drop_duplicates(inplace=True)\n",
    "all_schema=pd.merge(all_schema,temp.loc[:,['exam', 'q_num','log_freq']],on=['exam', 'q_num'])\n",
    "\n",
    "all_schema.loc[:,'log_freq'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s_d'></a>\n",
    "# d) All/None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All and none of the above questions may require some difficult logical processing from students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def contains_above(txt):\n",
    "    txt=' '.join([i.lower() for i in txt])\n",
    "    if 'all of the above' in txt or 'none of the above' in txt:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "the_above=all_schema.loc[:,['exam','q_num','answer']].groupby(['exam','q_num']).aggregate(contains_above).reset_index()\n",
    "the_above.columns=['exam','q_num','the_above']\n",
    "all_schema=pd.merge(all_schema,the_above,on=['exam', 'q_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_schema.the_above.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s_e'></a>\n",
    "## e) Answer-Answer Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar answers could have helped students by reducing the scope of possibilities they had to consider or acting as reminders or they could have hurt students by presenting virtually indistinguishable options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compare_text() function calculates, between two units of text, what proportion of words were shared (normalize by shorter text)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_text(txt1,txt2):\n",
    "    txt1_words=[w.lower() for w in str(txt1).split(' ')]\n",
    "    txt2_words=[w.lower() for w in str(txt2).split(' ')]    \n",
    "    min_len=min([len(txt1_words),len(txt2_words)])\n",
    "    if len(txt1_words)<len(txt2_words):\n",
    "        min_words=txt1_words\n",
    "        comp_words=txt2_words\n",
    "    else:\n",
    "        min_words=txt2_words        \n",
    "        comp_words=txt1_words\n",
    "    count=0\n",
    "    for w in min_words:\n",
    "        if w in comp_words:\n",
    "            count=count+1\n",
    "\n",
    "    return count/float(min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_text('hello','hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_sim_aa(group_df):\n",
    "    group_df.reset_index(inplace=True,drop=True)\n",
    "    curr_sim=[]\n",
    "    for i in range(len(group_df)):\n",
    "        for j in range(len(group_df)):\n",
    "            if i != j:\n",
    "\n",
    "                item_1=group_df[i]\n",
    "                item_2=group_df[j] \n",
    "                sim_prop=compare_text(item_1,item_2)\n",
    "                curr_sim.append(sim_prop)\n",
    "\n",
    "                \n",
    "    return np.mean(curr_sim)   \n",
    "\n",
    "aa_sim=all_schema.loc[:,['proc_answer','exam','q_num']].groupby(['exam','q_num']).aggregate(calc_sim_aa).reset_index()\n",
    "aa_sim.columns=['exam','q_num','aa_sim']\n",
    "all_schema.loc[:,'aa_sim']=pd.merge(all_schema,aa_sim,on=['exam','q_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119a4a310>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFVCAYAAAA30zxTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11912e810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_schema.loc[:,'aa_sim'].hist()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s_f'></a>\n",
    "## f) Question-Answer similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, questions that contained information about their answers could have contained clues for students "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_sim_qa(group_df):\n",
    "    group_df.reset_index(inplace=True,drop=True)\n",
    "    curr_sim=[]\n",
    "    for i in range(len(group_df)):\n",
    "\n",
    "        item_1=group_df.proc_answer[i]\n",
    "        item_2=group_df.proc_question[i] \n",
    "        sim_prop=compare_text(item_1,item_2)\n",
    "        curr_sim.append(sim_prop)\n",
    "                \n",
    "    return np.mean(curr_sim)   \n",
    "\n",
    "for e in np.unique(all_schema.exam):\n",
    "    curr_q=np.unique(all_schema.loc[all_schema.exam==e,'q_num'])\n",
    "    for q in curr_q:\n",
    "        sel_ind=np.logical_and(all_schema.exam==e,all_schema.q_num==q)\n",
    "        curr_qs=all_schema.loc[sel_ind,:]\n",
    "        all_schema.loc[sel_ind,'qa_sim']=calc_sim_qa(curr_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e in np.unique(all_schema.exam):\n",
    "    curr_q=np.unique(all_schema.loc[all_schema.exam==e,'q_num'])\n",
    "    for q in curr_q:\n",
    "        sel_ind=np.logical_and(all_schema.exam==e,all_schema.q_num==q)\n",
    "        curr_qs=all_schema.loc[sel_ind,:]\n",
    "        all_schema.loc[sel_ind,'qa_sim']=calc_sim_qa(curr_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118f36dd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFVCAYAAAA6zUwUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11954e590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_schema.loc[:,'qa_sim'].hist()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up: Combine data for lmer in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after all that, we've assembled a good number of features to predict students' performance on exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last4_ID</th>\n",
       "      <th>subject</th>\n",
       "      <th>instructor</th>\n",
       "      <th>q_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>q_len</th>\n",
       "      <th>ans_len</th>\n",
       "      <th>log_freq</th>\n",
       "      <th>the_above</th>\n",
       "      <th>aa_sim</th>\n",
       "      <th>qa_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "      <td>1</td>\n",
       "      <td>cognitive psychology_2</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>27.75</td>\n",
       "      <td>1.868999</td>\n",
       "      <td>False</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "      <td>2</td>\n",
       "      <td>cognitive psychology_3</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>61.25</td>\n",
       "      <td>1.506331</td>\n",
       "      <td>False</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "      <td>3</td>\n",
       "      <td>cognitive psychology_0</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.904348</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "      <td>4</td>\n",
       "      <td>cognitive psychology_2</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>57.25</td>\n",
       "      <td>2.053145</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>cognitive psychology</td>\n",
       "      <td>tflew</td>\n",
       "      <td>5</td>\n",
       "      <td>cognitive psychology_0</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>45</td>\n",
       "      <td>26.25</td>\n",
       "      <td>2.010838</td>\n",
       "      <td>True</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Last4_ID               subject instructor q_num                   topic  \\\n",
       "0      0_0  cognitive psychology      tflew     1  cognitive psychology_2   \n",
       "1      0_0  cognitive psychology      tflew     2  cognitive psychology_3   \n",
       "2      0_0  cognitive psychology      tflew     3  cognitive psychology_0   \n",
       "3      0_0  cognitive psychology      tflew     4  cognitive psychology_2   \n",
       "4      0_0  cognitive psychology      tflew     5  cognitive psychology_0   \n",
       "\n",
       "  answer correct  q_len  ans_len  log_freq the_above    aa_sim    qa_sim  \n",
       "0      a   False     29    27.75  1.868999     False  0.125000  0.000000  \n",
       "1      a    True     50    61.25  1.506331     False  0.888889  0.750000  \n",
       "2      b    True     55    14.00  1.904348     False  0.250000  0.000000  \n",
       "3      a    True     46    57.25  2.053145     False  0.000000  0.083333  \n",
       "4      a    True     45    26.25  2.010838      True  0.083333  0.112500  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields_to_transfer=['q_num','topic','q_len','ans_len','log_freq','the_above', 'aa_sim','qa_sim','subject','instructor']\n",
    "mc_test_data=pd.merge(all_resp_ans,all_schema.loc[:,fields_to_transfer])\n",
    "mc_test_data=mc_test_data.groupby([ 'Last4_ID','subject','instructor','q_num','topic','answer']).mean().reset_index()\n",
    "mc_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc_test_data.to_csv('exam_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And now we can go ahead and use this csv in R to find what factors predict people's performance!\n",
    "\n",
    "We'll want to use **lmer()** to build our model, gradually adding features, and **anova()** to check whether those features explain more of the variance. I looked around for a mixed effects model in Python, and there is some for in the statsmodel package, but it's limited a single random effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
